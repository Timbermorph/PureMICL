# ğŸ”¬ Multimodal In-Context Learning with Unsloth

This project implements training and inference pipelines for multimodal reasoning tasks using [Unsloth](https://github.com/unslothai/unsloth), built on top of `Qwen2-VL` and LoRA-based fine-tuning.

---

## âœ… Installation

### 1ï¸âƒ£ Clone this repository

```bash
git clone https://github.com/your_org/your_repo.git
cd your_repo
```
---

### 2ï¸âƒ£ Create virtual environment & activate (we recommend using python 3.11)

```bash
python3.11 -m venv unsloth_venv
source unsloth_venv/bin/activate
```
---

### 3ï¸âƒ£ Install all dependencies

```bash
pip install --upgrade pip
pip install -r pip_requirements.txt
```
---

### âš ï¸ Important: Unsloth version must match your PyTorch, CUDA, and GPU architecture

Unsloth must be installed with the correct tag depending on your hardware and environment. For example:

**âœ… Our working configuration:**
- GPU: A100 (Ampere)
- CUDA: 12.1
- PyTorch: 2.5.1

Use the following:

```txt
pip install --no-deps 'unsloth[cu121-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git'
```

If you use a different GPU or CUDA version, refer to [Unsloth install guide](https://github.com/unslothai/unsloth) and adjust accordingly.

---

## ğŸ“¦ Dataset Preparation

```bash
git clone https://huggingface.co/datasets/ShuoChen99/TrueMICL
```

Please download the required datasets from our data release and rename them as `dataset/` folder. For example:

```bash
dataset/
â”œâ”€â”€ operator_induction/
â”‚   â”œâ”€â”€ support.json
â”‚   â””â”€â”€ query.json
â”œâ”€â”€ sudoku/
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ shapes_count/
â”‚   â”œâ”€â”€ ...
...
```
---

## ğŸ§ª Running the Code

Running Training and Inference
This project provides a unified shell script run_main.sh for both training and inference.
For example, to run base model inference:

```bash
./run_infer.sh infer
```

| Mode            | Description |
|-----------------|-------------|
| `infer`         | Run inference with the base model. |
| `lora_infer`    | Run inference with a LoRA fine-tuned model. |
| `dara_infer`    | Run inference with a DARA model. |
| `lora_finetune` | Fine-tune with LoRA.Only part of the parameters are trainable. |
| `dara_finetune` | **DARA** training mode. |


**About the qwen2_vl_replacement Folder**

If a folder named qwen2_vl_replacement/ exists in the same directory as run_main.sh,
it will be automatically added to the highest priority in PYTHONPATH during script execution.

This means:

Files inside qwen2_vl_replacement/ will override the corresponding modules from the original transformers package.

Any files not present in qwen2_vl_replacement/ will still be loaded from the original package.

This mechanism allows you to replace or debug specific files without touching the original site-packages code â€” ideal for quick iteration and experiments.

> âš ï¸ Only one mode can be used at a time.  
> âš ï¸ Before running, **make sure to manually set the following variables inside `run_main.sh`**:

```bash
MODEL_PATH=/absolute/path/to/your/base_model
LORA_MODEL_PATH=./ckpt/your_checkpoint  # if using lora/dara_infer mode
```

---

### âœ… Output and Evaluation

After inference, results are saved under `./results/` in JSON format.

To calculate accuracy:

```bash
python check_accuracy.py ./results/your_result_file.json
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ ckpt/                         # Your LoRA checkpoints
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ dataset/                      # Place downloaded datasets here
â”‚   â”œâ”€â”€ operator_induction/
â”‚   â”œâ”€â”€ sudoku/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ qwen2_vl_replacement/    # Optional model override modules
â”œâ”€â”€ check_accuracy.py
â”œâ”€â”€ data_processing.py
â”œâ”€â”€ modeling_qwen2_vl.py
â”œâ”€â”€ pip_requirements.txt
â”œâ”€â”€ qwen2_finetune_new_model.py
â”œâ”€â”€ run_infer.sh                  # Entry script for training/inference
â”œâ”€â”€ samples_of_training_data.json
â””â”€â”€ readme.txt                   # (This README content)
```

---

## ğŸ“š References

- [Unsloth: Fast and Efficient Fine-tuning](https://github.com/unslothai/unsloth)
- [Qwen2-VL on HuggingFace](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct)
