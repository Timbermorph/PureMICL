# ğŸ”¬ Multimodal In-Context Learning with Unsloth

This project implements training and inference pipelines for multimodal reasoning tasks using [Unsloth](https://github.com/unslothai/unsloth), built on top of `Qwen2-VL` and LoRA-based fine-tuning.

---

## âœ… Installation (Python 3.11, Linux, CUDA 12.1)

We recommend using `venv` and pinned dependencies for reproducibility. These instructions assume you're using an A100 GPU (Ampere architecture) and PyTorch 2.5.1 + CUDA 12.1.

### Create a virtual environment

```bash
python3.11 -m venv unsloth_venv
source unsloth_venv/bin/activate
```
---
---

### Install project dependencies

```bash
pip install -r requirements.txt
```

> `unsloth[...] @ git+https://...` in the `requirements.txt` must match your CUDA and PyTorch versions. See [Unsloth install guide](https://github.com/unslothai/unsloth) for custom combinations.

---

## ğŸ§ª Running the Code

### 4ï¸âƒ£ Run training or inference

```bash
bash run_main.sh [infer|lora_infer|finetune]

| Mode         | Description                                 |
|--------------|---------------------------------------------|
| `finetune`   | Finetune the model on your training dataset |
| `infer`      | Run inference with base model               |
| `lora_infer` | Run inference with LoRA fine-tuned model    |

> âš™ï¸ You must set the `MODEL_PATH` in `run_main.sh` before using it:

```bash
MODEL_PATH=/path/to/your/base_model

---

### 5ï¸âƒ£ Evaluate output accuracy

After inference, your results will be saved in `./results/*.json`.

```bash
python check_accuracy.py ./results/your_result_file.json

Example output:

```
Total Samples: 100
Correct Predictions: 92
Accuracy: 92.00%
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ requirements.txt           # All dependencies (pinned)
â”œâ”€â”€ run_main.sh                # Entrypoint for training/inference
â”œâ”€â”€ check_accuracy.py          # Accuracy evaluation
â”œâ”€â”€ qwen2_finetune_new_model.py# Main training/inference script
â”œâ”€â”€ dataset/                   # Your preprocessed data
â”‚   â”œâ”€â”€ operator_induction/
â”‚   â”‚   â”œâ”€â”€ support.json
â”‚   â”‚   â””â”€â”€ query.json
â””â”€â”€ results/
    â””â”€â”€ your_result_file.json
```

---

## ğŸ“Œ Notes

- Only Python 3.10 â€“ 3.12 are supported by Unsloth (3.13 is not supported).
- If you switch GPUs or CUDA versions, modify this line in `requirements.txt`:

```txt
unsloth[cu121-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git

- For help tuning `n_values`, `query_limit`, or datasets, check `run_main.sh`.

---

## ğŸ“š Citation & References

- [Unsloth: Fast and Efficient Fine-tuning](https://github.com/unslothai/unsloth)
- [Qwen2-VL on HuggingFace](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct)
